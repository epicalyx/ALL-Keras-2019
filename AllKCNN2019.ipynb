{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllKCNN2019.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nsx2WMTeKoc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Introduction\n",
        "\n",
        "### - This notebook explores a novel convolutional network architechture as discussed in the following research paper to build a classification system for better assistance in diagonosing Acute Lymphoblastic Leukemia in blood cells.\n",
        "**[Research Paper](http://www.ijcte.org/vol10/1198-H0012.pdf)**\n",
        "\n",
        "\n",
        "### - To gain access to the dataset, please visit [here](https://homes.di.unimi.it/scotti/all/#download) and to contribute back to the project, [here](https://homes.di.unimi.it/scotti/all/results.php)\n",
        "\n",
        "* Here, ALL_IDB2 version of the dataset has been used\n",
        "\n",
        "* This dataset is completely balanced with equal number of samples in both the classes.\n",
        "\n",
        "\n",
        "### - Data augmentation ensures that data is large enough and model extracts features efficiently without overfitting and therefore we have analysed the following types of data augmentation techniques in this notebook\n",
        "* Techniques used in the research paper discussing the following parameters:\n",
        "\n",
        "   1. Grayscaling of image\n",
        "   2. Horizontal reflection\n",
        "   3. Vertical reflection\n",
        "   4. Gaussian Blurring\n",
        "   5. Histogram Equalization\n",
        "   6. Rotation\n",
        "   7. Translation\n",
        "   8. Shearing\n",
        "   \n",
        "Only training data was augmented. The training dataset contains upto 1170 images after augmentation. The test set has 130 images(10% of the whole dataset)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### - The results of our present analysis is:\n",
        "\n",
        "| Data Augmentation    | Accuracy   | Precision   | Recall   |  ROC |\n",
        "|---|---|---|---|--|\n",
        "| Used in paper   | 91.5%  | 0.96  | 0.85  | 0.98  |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**This result has been recorded for maximum number of epochs that model could be trained for without overfitting**\n",
        "\n",
        "**The model has then been quantized so as to ease its deployment on edge devices**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Below is the detailed code implementation of this research paper "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfZJS4lHhUXE",
        "colab_type": "text"
      },
      "source": [
        "## **Loading requires packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CimI3AcDR3kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ8BE0xmnLD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from numpy.random import seed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import ndimage\n",
        "from skimage import exposure\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage import transform as tm\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import tensorflow.keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model,Sequential,model_from_json\n",
        "from keras.layers import Dense,Flatten,Activation\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Input,GaussianNoise\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "import keras_metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam,RMSprop,SGD\n",
        "from sklearn.metrics import confusion_matrix,precision_score,recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras import backend as K\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKP9GmW2I7wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tensorflow.keras.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH2z2eQB6ZpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for consistemt results across multiple executions\n",
        "seed(3)\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJ5j1oTk_vg",
        "colab_type": "text"
      },
      "source": [
        "## **Mount your Google Drive**\n",
        "\n",
        " \n",
        "\n",
        "##### **Use the following commands to mount your Google Drive.**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta29xTTR9Ih4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USo9i0zB-r1c",
        "colab_type": "text"
      },
      "source": [
        "##### **Using the commands below, you can upload the ALL-Keras-2019 directory from your cloned repo, here and unzip to the root of your Google Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJyMELFc-sZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!unzip -uq \"ALL-Keras-2019.zip\" -d \"/content/gdrive/My Drive/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHsmyUQ_vH-s",
        "colab_type": "text"
      },
      "source": [
        "#### **You will notice the data folder in the Model directory, Model/Data, inside you have Train and Test.**\n",
        "\n",
        "#### **You can place all the images inside the *Train* folder. We will split them into training and test set below**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJwo22WNpQjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = \"/content/gdrive/My Drive/ALL-Keras-2019/\"\n",
        "data_dir = 'Model/Data/Train'\n",
        "dataset = Path(root_dir + data_dir)\n",
        "images= dataset.glob(\"*.tif\")\n",
        "data = []\n",
        "\n",
        "for img in images:\n",
        "  name, ext = os.path.splitext(os.path.basename(img))\n",
        "  if name[-1]=='1':\n",
        "    data.append((img,1))\n",
        "  elif name[-1]=='0':\n",
        "    data.append((img,0))\n",
        "    \n",
        "data_frame = pd.DataFrame(data,columns=['image','label'],index = None)\n",
        "data_frame = data_frame.sample(frac=1.).reset_index(drop=True)\n",
        "data_frame.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsDVRHjJnzb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Splitting training and test data; we will not be augmenting test data\n",
        "train = pd.DataFrame()\n",
        "test = pd.DataFrame()\n",
        "\n",
        "train = data_frame[:130]\n",
        "test = data_frame[130:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zewhaj6Ul0Y_",
        "colab_type": "text"
      },
      "source": [
        "## **Data Exploration and Augmentation as presented in the paper**\n",
        "\n",
        "\n",
        "### 8 augmentation techniques have been used here\n",
        "1. Grayscaling of image\n",
        "2. Horizontal reflection \n",
        "3. Vertical reflection\n",
        "4. Gaussian Blurring \n",
        "5. Histogram Equalization\n",
        "6. Rotation\n",
        "7. Translation\n",
        "8. Shearing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f71MR6OdWyJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# histogram equalization function\n",
        "def hist(img):\n",
        "  img_to_yuv = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
        "  img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])\n",
        "  hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
        "  return hist_equalization_result\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81rPbbtegU2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to perform rotation on an image\n",
        "def rotation(img):\n",
        "  rows,cols = img.shape[0],img.shape[1]\n",
        "  randDeg = random.randint(-180, 180)\n",
        "  matrix = cv2.getRotationMatrix2D((cols/2, rows/2), randDeg, 0.70)\n",
        "  rotated = cv2.warpAffine(img, matrix, (rows, cols), borderMode=cv2.BORDER_CONSTANT,\n",
        "                                     borderValue=(144, 159, 162))\n",
        "  return rotated     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urz26j6qZJFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to perform shearing of an image\n",
        "def shear(img):\n",
        "  # Create Afine transform\n",
        "  afine_tf = tm.AffineTransform(shear=0.5)\n",
        "  # Apply transform to image data\n",
        "  modified = tm.warp(img, inverse_map=afine_tf)\n",
        "  return modified"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYS6DhKxKrvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aug_method(dataframe,dim,method):\n",
        "  if method == 'paper':\n",
        "    n = len(dataframe)\n",
        "    data = np.zeros((n*9,dim,dim,3),dtype = np.float32)\n",
        "    labels = np.zeros((n*9,2),dtype = np.float32)\n",
        "    count = 0\n",
        "\n",
        "    for j in range(0,n):\n",
        "      img_name = dataframe.iloc[j]['image']\n",
        "      label = dataframe.iloc[j]['label']\n",
        "\n",
        "      encoded_label = np_utils.to_categorical(label, num_classes=2)\n",
        "\n",
        "      img = cv2.imread(str(img_name))\n",
        "      img = cv2.resize(img, (dim,dim))\n",
        "\n",
        "      if img.shape[2]==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "\n",
        "      orig_img = img.astype(np.float32)/255.\n",
        "      data[count] = orig_img\n",
        "      labels[count] = encoded_label\n",
        "      \n",
        "      aug_img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      aug_img2 = cv2.flip(img, 0) \n",
        "      aug_img3 = cv2.flip(img,1)\n",
        "      aug_img4 = ndimage.gaussian_filter(img, sigma= 5.11)\n",
        "      aug_img5 = hist(img)\n",
        "      aug_img6 = rotation(img)\n",
        "      aug_img7 = cv2.warpAffine(img, np.float32([[1, 0, 84], [0, 1, 56]]), (img.shape[0], img.shape[1]),\n",
        "                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(144, 159, 162))\n",
        "      aug_img8 = shear(img)\n",
        "      aug_img1 = np.dstack([aug_img1, aug_img1, aug_img1])\n",
        "\n",
        "\n",
        "      aug_img1 = aug_img1.astype(np.float32)/255.                 \n",
        "      aug_img2 = aug_img2.astype(np.float32)/255.\n",
        "      aug_img3 = aug_img3.astype(np.float32)/255. \n",
        "      aug_img4 = aug_img4.astype(np.float32)/255.\n",
        "      aug_img5 = aug_img5.astype(np.float32)/255.\n",
        "      aug_img6 = aug_img6.astype(np.float32)/255.\n",
        "      aug_img7 = aug_img7.astype(np.float32)/255.\n",
        "      aug_img8 = aug_img8.astype(np.float32)/255.\n",
        "\n",
        "      data[count+1] = aug_img1\n",
        "      labels[count+1] = encoded_label\n",
        "      data[count+2] = aug_img2\n",
        "      labels[count+2] = encoded_label\n",
        "      data[count+3] = aug_img3\n",
        "      labels[count+3] = encoded_label\n",
        "      data[count+4] = aug_img4\n",
        "      labels[count+4] = encoded_label\n",
        "      data[count+5] = aug_img5\n",
        "      labels[count+5] = encoded_label\n",
        "      data[count+6] = aug_img5\n",
        "      labels[count+6] = encoded_label\n",
        "      data[count+7] = aug_img5\n",
        "      labels[count+7] = encoded_label\n",
        "      data[count+8] = aug_img5\n",
        "      labels[count+8] = encoded_label\n",
        "\n",
        "      count +=9\n",
        "      \n",
        "  elif method == 'keras':\n",
        "    n = len(dataframe)\n",
        "    data = np.zeros((n,dim,dim,3),dtype = np.float32)\n",
        "    labels = np.zeros((n,2),dtype = np.float32)\n",
        "    count = 0\n",
        "    \n",
        "    for j in range(0,n):    \n",
        "      img_name = dataframe.iloc[j]['image']\n",
        "      label = dataframe.iloc[j]['label']\n",
        "      \n",
        "      encoded_label = np_utils.to_categorical(label, num_classes=2)\n",
        "            \n",
        "      img = cv2.imread(str(img_name))\n",
        "      img = cv2.resize(img, (dim,dim))\n",
        "      \n",
        "      if img.shape[2]==1:   \n",
        "        img = np.dstack([img, img, img])\n",
        "                                   \n",
        "      orig_img = img.astype(np.float32)/255.\n",
        "                        \n",
        "      data[count] = orig_img\n",
        "      labels[count] = encoded_label\n",
        "    \n",
        "      count +=1      \n",
        "  return data,labels                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTe3UIOoFhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, labels_train = aug_method(train,dim=100,method='paper')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs2o_i_zg_lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_prep(dataframe,dim):    \n",
        "  n = len(dataframe)\n",
        "  data = np.zeros((n,dim,dim,3),dtype = np.float32)\n",
        "  labels = np.zeros((n,2),dtype = np.float32)\n",
        "  count = 0\n",
        "\n",
        "  for j in range(0,n):\n",
        "    img_name = dataframe.iloc[j]['image']\n",
        "    label = dataframe.iloc[j]['label']\n",
        "\n",
        "    encoded_label = np_utils.to_categorical(label, num_classes=2)\n",
        "\n",
        "    img = cv2.imread(str(img_name))\n",
        "    img = cv2.resize(img, (dim,dim))\n",
        "\n",
        "    if img.shape[2]==1:\n",
        "      img = np.dstack([img, img, img])\n",
        "\n",
        "    orig_img = img.astype(np.float32)/255.\n",
        "\n",
        "    data[count] = orig_img\n",
        "    labels[count] = encoded_label\n",
        "    count+=1\n",
        "  return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQC9YHT1oWXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test,labels_test = test_prep(test,dim=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viodvfyvmDSS",
        "colab_type": "text"
      },
      "source": [
        "## **Visualizing dataset images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLuFjhqsDsAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.argmax(labels_train, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UUxV0Jo9zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, ax = plt.subplots(4,5, figsize=(30,7))\n",
        "for i in range(0,20):\n",
        "    ax[i//5, i%5].imshow(data_train[i])\n",
        "    if y[i]==1:\n",
        "        ax[i//5, i%5].set_title(\"Non-ALL\")\n",
        "    else:\n",
        "        ax[i//5, i%5].set_title(\"ALL\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh2eNGw2U9jK",
        "colab_type": "text"
      },
      "source": [
        "### **Splitting into training and test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVhGNDOp4SpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = data_train,data_test,labels_train,labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ6ER15cwwrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of training data\",X_train.shape)\n",
        "print(\"Shape of testing data\",X_test.shape)\n",
        "print(\"Shape of training labels\",y_train.shape)\n",
        "print(\"Shape of testing labels\",y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAQNIXMpPv7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "###**The following model was used in the paper**\n",
        "Additionaly three dropout layers with different dropout rates have been used to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6-Em20CpBof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(16,(5,5),padding='valid',input_shape = X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(5,5),padding='valid'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'))\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(5,5),padding='valid'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.8))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(2,activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnjtIKJqt28j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I60o6qEQleL4",
        "colab_type": "text"
      },
      "source": [
        "### **Model compilation and fitting**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tw9CHEPMz1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "epochs= 300\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.0001, decay = 1e-6)\n",
        "model.compile(loss = 'binary_crossentropy',optimizer = optimizer, metrics = ['accuracy',keras_metrics.precision(), keras_metrics.recall()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRUmoNa_xTR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train,y_train,steps_per_epoch = int(len(X_train)/batch_size),epochs=epochs)\n",
        "history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wDXMNf2zgd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test,y_test,verbose=0)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrWXe4NOzmYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iquoDxPyscPR",
        "colab_type": "text"
      },
      "source": [
        "**Result for 300 epochs**\n",
        "\n",
        "**1.Accuracy -91.5%**\n",
        "\n",
        "**2.Precision -0.96**\n",
        "\n",
        "**3.Recall -0.85**\n",
        "\n",
        "**4. AUC score -0.98**\n",
        "\n",
        "\n",
        "The model stops learning after 300 epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rziaoBkmq2I",
        "colab_type": "text"
      },
      "source": [
        "### **Visualizing accuracy and loss**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifHI_ja5zxop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2keg8LDnBFu",
        "colab_type": "text"
      },
      "source": [
        "### Saving model into \".json\" format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDJ_sV-sAvjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"model.json\", \"w\") as file:\n",
        "    file.write(model.to_json())\n",
        "\n",
        "model.save(filepath = '/content/model.h5')\n",
        "model.save_weights(filepath = \"/content/weights.h5\",overwrite=True, save_format=\"h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}